# ğŸš€ LLM Guardrail Inference Pipeline

*A lightweight, production-ready backend for secure LLM inference, fully open-source.*

This project implements a modern LLM backend featuring:

* ğŸ§  **LLM text generation** using HuggingFace Transformers
* ğŸ” **Safety guardrails**: PII detection, harmful content filtering, hallucination heuristics
* ğŸ“¦ **Structured outputs** with Pydantic v2
* ğŸ¤– **Agent tool-calling** (â€œMCP-styleâ€) â€” includes a real working UTC-time tool
* ğŸ—„ï¸ **Persistent interaction logging** via SQLModel + SQLite
* âš¡ **FastAPI REST API** with full Swagger / OpenAPI documentation
* ğŸ”§ **Configurable model loading** (TinyLlama, Phi-2, Phi-1.5 Mini, etc.)

This serves as a **lightweight open-source alternative** to:
GuardrailsAI â€¢ OpenAI Moderation â€¢ Anthropic Constitutional AI
â€¦but implemented fully from scratch for transparency, learning, and extensibility.

---

## âœ¨ Key Features

### ğŸ§  1. HuggingFace LLM Text Generation

* Supports any open HuggingFace causal model
* TinyLlama (default), Phi-2, Phi-1.5 Mini, GPT-like endpoints
* Clean generation pipeline with temperature, top-k, max tokens

### ğŸ” 2. Custom Guardrail System

Includes:

* PII detectors (regex-based)
* Unsafe-content filters
* Hallucination heuristics (unverifiable citations, fake references)
* Unified `GuardrailFlags` schema for downstream consumption

### ğŸ¤– 3. Agent Tool-Calling (â€œMCP Styleâ€)

* Pluggable tools
* Example: UTC Time Lookup
* Framework ready for additional tools (web search, DB query, file ops, etc.)

### ğŸ—„ï¸ 4. Persistent Logging

* Uses **SQLModel + SQLite**
* Stores prompts, responses, guardrail triggers, timestamps, and model metadata
* Perfect for dashboards, RLHF datasets, or audits

### âš¡ 5. FastAPI Backend with Auto Docs

Once running:

* **Swagger UI:**
  ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

* **OpenAPI schema:**
  ğŸ‘‰ [http://127.0.0.1:8000/openapi.json](http://127.0.0.1:8000/openapi.json)

---

## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/LLM-Guardrail-Pipeline.git
cd LLM-Guardrail-Pipeline
```

### 2ï¸âƒ£ Create & activate a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

**Optional: Enable GPU/MPS acceleration**

```bash
pip install "accelerate>=0.26.0"
```

---

## â–¶ï¸ Running the Server

Start the API server:

```bash
uvicorn app.main:app --reload
```

Server will be live at:
ğŸ‘‰ **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

## ğŸ§© Project Structure

```
app/
 â”œâ”€â”€ main.py               # FastAPI entry point
 â”œâ”€â”€ pipelines.py          # LLM generation + guardrail integration
 â”œâ”€â”€ guardrails.py         # Safety filtering, PII, hallucinations
 â”œâ”€â”€ schemas.py            # Pydantic models (requests/responses)
 â”œâ”€â”€ mcp_agent.py          # Tool-calling agent
 â””â”€â”€ logging_utils.py      # SQLModel/SQLite persistence
```

---

## ğŸŒŸ Why This Project Matters

This repository demonstrates real-world skills involved in AI engineering:

* Building **production-grade LLM APIs**
* Implementing **custom safety + guardrail systems**
* Using **FastAPI, SQLModel, Pydantic v2, and HuggingFace**
* Designing **modular and extensible AI systems**
* Supporting **agent tool-calling patterns similar to MCP**
